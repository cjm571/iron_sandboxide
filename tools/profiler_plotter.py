""" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " "
Filename : tools/metrics_receiver.rs

Copyright (C) 2020 CJ McAllister
    This program is free software; you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation; either version 3 of the License, or
    (at your option) any later version.
    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.
    You should have received a copy of the GNU General Public License
    along with this program; if not, write to the Free Software Foundation,
    Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA

Purpose: 
    This file is used to parse the large CSV files generated by the
    SandCasting performance profiler.

" " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " " """

import csv
import sys
import time

import matplotlib.pyplot as plt
import numpy as np

def usage():
    print("Usage: python profiler_plotter.py \\path\\to\\metrics\\dir\\ PROFILER_DATA_FILE1.csv [PROFILER_DATA_FILE2.csv]")


def parse_numerical_data(filename):
    # Retrieve float data from csv
    timestamps = []
    values = []

    print("Parsing numerical data in " + filename + "...", end='')
    parse_start_time = time.time()

    # Open data file for parsing
    with open(filename) as csvDataFile:

        # Use ; as delimiter to expose the (timestamp, value) tuples
        csvReader = csv.reader(csvDataFile, delimiter=';')
        for row in csvReader:
            for data_tuple in row:
                # Break once we encounter an empty column
                if data_tuple == '':
                    break

                # Split data tuples on ','
                (timestamp, value) = data_tuple.split(',')

                # Determine data type and cast accordingly
                if '.' in timestamp:
                    timestamps.append(float(timestamp))
                else:
                    timestamps.append(int(timestamp))

                # Determine data type and cast accordingly
                if '.' in value:
                    values.append(float(value))
                else:
                    values.append(int(value))
    
    # Return collated data tuple
    parse_stop_time = time.time()
    delta = parse_stop_time - parse_start_time
    print(" Complete! (" + str(delta) + ")")
    return (timestamps, values)


def parse_string_data(filename):
    # Retrieve float data from csv
    timestamps = []
    dummy_vals = []
    labels = []

    print("Parsing string data in " + filename + "...", end='')
    parse_start_time = time.time()

    # Open data file for parsing
    with open(filename) as csvDataFile:

        # Use ; as delimiter to expose the (timestamp, value) tuples
        csvReader = csv.reader(csvDataFile, delimiter=';')
        for row in csvReader:
            for data_tuple in row:
                # Break once we encounter an empty column
                if data_tuple == '':
                    break

                # Split data tuples on ','
                (timestamp, label) = data_tuple.split(',')

                # Determine data type and cast accordingly
                if '.' in timestamp:
                    timestamps.append(float(timestamp))
                else:
                    timestamps.append(int(timestamp))
                    
                # Add data to arrays
                labels.append(label)
                dummy_vals.append(1)
    
    # Return collated data tuple
    parse_stop_time = time.time()
    delta = parse_stop_time - parse_start_time
    print(" Complete! (" + str(delta) + ")")
    return (timestamps, labels, dummy_vals)


def parse_stacked_data(filename):
    # Retrieve float data from csv
    timestamps = []
    parsed_stacks = []

    print("Parsing stacked data in " + filename + "...", end='')
    parse_start_time = time.time()

    # Open data file for parsing
    with open(filename) as csvDataFile:

        # Use ; as delimiter to expose the (timestamp, stacks) tuples
        csvReader = csv.reader(csvDataFile, delimiter=';')
        for row in csvReader:
            for data_tuple in row:
                # Break once we encounter an empty column
                if data_tuple == '':
                    break

                # Split data tuples on ','
                (timestamp, stack_string) = data_tuple.split(',')

                # Determine data type and cast accordingly
                if '.' in timestamp:
                    timestamps.append(float(timestamp))
                else:
                    timestamps.append(int(timestamp))

                # Split stacked values on '|'
                parsed_stack = []
                stack_values = stack_string.split('|')
                for value in stack_values:
                    # Determine data type and cast accordingly
                    if '.' in value:
                        parsed_stack.append(float(value))
                    else:
                        parsed_stack.append(int(value))
                
                # Append parsed stack and clear for next iteration
                parsed_stacks.append(parsed_stack)

    parse_stop_time = time.time()
    delta = parse_stop_time - parse_start_time
    print(" Complete! (" + str(delta) + ")")

    # Return collated data tuple
    print("Collating data...", end='')
    collated_stacks = []
    for i in range(len(parsed_stacks[0])):
        collated_stack = []
        for j in range(len(timestamps)):
            collated_stack.append(parsed_stacks[j][i])
        collated_stacks.append(collated_stack)

    collation_stop_time = time.time()
    delta = collation_stop_time - parse_stop_time
    print(" Complete! (" + str(delta) + ")")
    return (timestamps, collated_stacks)


def populate_axis(axis, color, filepath):
    # Parse CSV file based on metric type
    filename = filepath.split('\\')[-1]

    if filename == "avg_fps.csv":
        axis.set_ylabel('Avg FPS', color=color)
        (timestamps, values) = parse_numerical_data(filepath)
        axis.plot(timestamps, values, color=color)
        
    elif filename == "frame_delta.csv":
        axis.set_ylabel('Frame Delta (sec)', color=color)
        (timestamps, values) = parse_numerical_data(filepath)
        axis.plot(timestamps, values, color=color)

    elif filename == "event_marker.csv":
        event_offset_dict = {}
        offset = 0.0
        (timestamps, labels, dummy_vals) = parse_string_data(filepath)

        # Use timestamps and dummy values for the bar chart
        axis.bar(timestamps, dummy_vals, color=color, width=0.5)
        axis.set_yticks([])


        # Annotate chart with event labels
        for i in range(len(timestamps)):
            # Assign offsets for each event type
            if labels[i] not in event_offset_dict:
                event_offset_dict[labels[i]] = offset
                offset += 0.1
            
            # Place "STOP" events slightly below "START" for readability
            if  "START" in labels[i]:
                axis.annotate(labels[i], xy=[timestamps[i], dummy_vals[i] - event_offset_dict.get(labels[i])])
            elif "STOP" in labels[i]:
                axis.annotate(labels[i], xy=[timestamps[i], dummy_vals[i] - event_offset_dict.get(labels[i]) - 0.05])
            else:
                axis.annotate(labels[i], xy=[timestamps[i], dummy_vals[i] - event_offset_dict.get(labels[i])])

    elif filename == "stacked_draw_time.csv":
        axis.set_ylabel('Stacked Draw Times (sec)', color=color)
        (timestamps, collated_stacks) = parse_stacked_data(filepath)
        
        print("Creating stack bar charts...", end='')
        create_stack_start_time = time.time()

        # Create list of bar charts to be stacked
        axis.bar(timestamps, collated_stacks[0])
        axis.bar(timestamps, collated_stacks[1], bottom=collated_stacks[0])
        bottoms = np.add(collated_stacks[0], collated_stacks[1]).tolist()
        axis.bar(timestamps, collated_stacks[2], bottom=bottoms)

        for i in range(3, len(collated_stacks)):
            bottoms = np.add(bottoms, collated_stacks[i-1]).tolist()
            axis.bar(timestamps, collated_stacks[i], bottom=bottoms)

        create_stack_stop_time = time.time()
        delta = create_stack_stop_time - create_stack_start_time
        print(" Complete! (" + str(delta) + ")")

    else:
        print("Invalid file provided:" + filepath)
        sys.exit(3)


if __name__ == "__main__":
    # Sanity check command-line arguments
    if len(sys.argv) < 2:
        usage()
        sys.exit(2)

    # Intialize chart boilerplate
    fig, ax0 = plt.subplots()
    color = 'tab:blue'
    ax0.set_xlabel('time (ms)')

    # Populate the first chart axis
    metrics_dir = sys.argv[1]

    print("Populating 1st axis...")
    populate_axis(ax0, color, metrics_dir + sys.argv[2])

    # Populate the second chart axis, if file provided
    if len(sys.argv) > 3:
        print("Populating 2nd axis...")
        ax1 = ax0.twinx()
        color = 'tab:red'
        
        populate_axis(ax1, color, metrics_dir + sys.argv[3])

    # Populate the third chart axis, if file provided
    if len(sys.argv) > 4:
        print("Populating 3rd axis...")
        ax2 = ax0.twinx()
        color = 'tab:green'
        
        populate_axis(ax2, color, metrics_dir + sys.argv[4])

    print("Constructing plot...")

    # Construct figure title
    timestamp = metrics_dir.split('\\')[-2]
    fig.suptitle("SandCasting Performance Profiling Data (" + timestamp + ")")
    plt.gcf().canvas.set_window_title("SandCasting Profiler Parser")
    plt.show()
